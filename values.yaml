jarvice:
  imagePullRegistries:
    - us-docker.pkg.dev
    - europe-docker.pkg.dev
    - asia-docker.pkg.dev
    - gcr.io
  # imagePullSecret is a base64 encoded string.
  # e.g. on command line: echo "_json_key:$(cat key.json)" | base64 -w 0
  imagePullSecret:
  JARVICE_LICENSE_LIC:

  # JARVICE_REMOTE_* settings are used for application synchronization
  JARVICE_REMOTE_API_URL: https://cloud.nimbix.net/api
  JARVICE_REMOTE_USER:
  JARVICE_REMOTE_APIKEY:
  JARVICE_APPSYNC_USERONLY: "false"

  JARVICE_LOCAL_REGISTRY: # jarvice-registry:5000
  JARVICE_LOCAL_REPO_BASE: jarvice

  JARVICE_REGISTRY_PROXY_REPOS: "us-docker.pkg.dev/jarvice,us-docker.pkg.dev/jarvice-system,us-docker.pkg.dev/jarvice-apps"

  JARVICE_SYSTEM_REGISTRY: us-docker.pkg.dev
  JARVICE_SYSTEM_REPO_BASE: jarvice-system/images
  JARVICE_IMAGES_TAG: jarvice-master
  JARVICE_IMAGES_VERSION: # auto-set (ignored) if installing from chart repo

  # Optionally, run jobs on a "downstream" cluster by default
  JARVICE_DEFAULT_CLUSTER_URL: # "https://jarvice.downstream-domain.com"

  # If JARVICE_CLUSTER_TYPE is not set to "downstream", an "upstream" cluster
  # deployment/configuration is assumed.
  # If JARVICE_CLUSTER_TYPE is set to "downstream", relevant "upstream"
  # settings in jarvice_* component stanzas are ignored.
  JARVICE_CLUSTER_TYPE: "upstream"  # "downstream"

  # If deploying "downstream" cluster, be sure to set JARVICE_SCHED_SERVER_KEY
  JARVICE_SCHED_SERVER_KEY: # "jarvice-downstream:Pass1234"

  # JARVICE_JOBS_DOMAIN: # jarvice.my-domain.com/job$   # (path based ingress)
  JARVICE_JOBS_DOMAIN: # my-domain.com  # (host based ingress)
  JARVICE_JOBS_INGRESS_ANNOTATIONS: # '{"nginx.org/mergeable-ingress-type": "minion", "nginx.org/client-max-body-size": "0", "nginx.org/proxy-read-timeout": "3600", "nginx.org/proxy-send-timeout": "3600"}'
  JARVICE_JOBS_LB_SERVICE: "false"
  JARVICE_JOBS_LB_ANNOTATIONS: # '{}'
  JARVICE_JOBS_MULTI_TENANT: "false"
  # At least one of JARVICE_JOBS_MULTI_TENANT_* must be set to a non-empty
  # set/list to enable access to interactive jobs via per job NetworkPolicy
  JARVICE_JOBS_MULTI_TENANT_INGRESS_POD_LABELS: '{}' # '{"app": "traefik"}'
  JARVICE_JOBS_MULTI_TENANT_INGRESS_NS_LABELS: '{}' # '{"name": "kube-system"}'
  JARVICE_JOBS_MULTI_TENANT_LB_SERVICE_CIDRS: '[]' # '["10.20.0.0/24"]'
  JARVICE_JOBS_IMAGE_PULL_POLICY: Always

  # jarvice.tolerations applies to all of the jarvice_* components below.
  # This can be overridden by updating tolerations in each jarvice_* stanza.
  tolerations: '[{"key": "node-role.jarvice.io/jarvice-system", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-system", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-system", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-system", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-system": "true"}'

  # JARVICE_DBHOST and JARVICE_DBUSER only need to change if using a database
  # not provided by this helm chart
  JARVICE_DBHOST: jarvice-db
  JARVICE_DBUSER: root
  JARVICE_DBPASSWD: Pass1234

  JARVICE_PVC_VAULT_NAME: persistent
  JARVICE_PVC_VAULT_STORAGECLASS: jarvice-user
  JARVICE_PVC_VAULT_VOLUMENAME:   # do not use with dynamic provisioning
  JARVICE_PVC_VAULT_ACCESSMODES:  # e.g. "ReadWriteMany,ReadOnlyMany"
  JARVICE_PVC_VAULT_SIZE:         # gigabytes
  JARVICE_PVC_VAULT_SUBPATH:      # optional subpath (supports substitutions)
  JARVICE_PVC_VAULT_ZONE:         # optional zone ID for vault (defaults to 0 - default)

  JARVICE_PVCRUN_CPU_REQUEST: "200m"  # cpu request for file lister - set to "1" for large single volumes shared by many users
  JARVICE_PVCRUN_CPU_LIMIT: "500m"    # cpu limit for file lister - set to "2" for large single volumes shared by many users
  JARVICE_PVCRUN_EXPIRE_SECS: "90"    # how long to keep file lister pods running idle before terminating

  JARVICE_EPHEMERAL_VAULT_ZONE:   # (defaults to -1 if not set)
  JARVICE_DAL_HOOK_META:          # opaque (unset by default)

  JARVICE_APP_ALLOW_ROOT_INIT:            # allows root appdefv2 apps init, default to false
  JARVICE_APP_ALLOW_PRIVILEGE_ESCALATION: # allows sudo inside appdefv2 apps, default to false

  JARVICE_DATA_CHOWN: # set to "false" to prevent chown of /data

  JARVICE_POD_SCHED_LOGLEVEL: 30
  JARVICE_SCHED_PASS_LOGLEVEL: 30
  JARVICE_SCHED_LOGLEVEL: 30
  JARVICE_K8S_SCHED_LOGLEVEL: 30
  JARVICE_API_LOGLEVEL: 30
  JARVICE_LICENSE_MANAGER_LOGLEVEL: 10

  # JARVICE_LICENSE_MANAGER_URL is auto-set in "upstream" deployments if
  # jarvice_license_manager.enabled is true (may still be modified as needed)
  JARVICE_LICENSE_MANAGER_URL: # "https://jarvice-license-manager.my-domain.com"
  JARVICE_LICENSE_MANAGER_SSL_VERIFY: "true"
  JARVICE_LICENSE_MANAGER_KEY: "jarvice-license-manager:Pass1234"

  # HTTP/S Proxy settings, no_proxy is set for services
  JARVICE_HTTP_PROXY:          # "http://proxy.my-domain.com:8080"
  JARVICE_HTTPS_PROXY:         # "https://proxy.my-domain.com:8080"
  JARVICE_NO_PROXY:            # "my-other-domain.com,192.168.1.10,domain.com:8080"
  JARVICE_K8S_CLUSTER_DOMAIN:  # "cluster.local"

  JARVICE_MAIL_SERVER: jarvice-smtpd:25
  JARVICE_MAIL_USERNAME: # "mail-username"
  JARVICE_MAIL_PASSWORD: # "Pass1234"
  JARVICE_MAIL_ADMINS: # "admin1@my-domain.com,admin2@my-domain.com"
  JARVICE_MAIL_FROM: "JARVICE Job Status <DoNotReply@localhost>"
  JARVICE_PORTAL_MAIL_FROM: "JARVICE Account Status <DoNotReply@localhost>"
  JARVICE_PORTAL_MAIL_SUBJECT: "Your JARVICE Account"

  # Long-running job (LRJ) email notification settings; see LRJ.md for details
  JARVICE_LRJ_WALLTIME:       # hours; must be >0 to enable LRJ notifications
  JARVICE_LRJ_PERIOD: 24      # hours
  JARVICE_LRJ_BATCH:  "false" # true|false
  JARVICE_LRJ_PAYER_NOTIFY: "false" # true|false
  JARVICE_LRJ_OWNER_BLACKLIST:  # comma-separated list
  JARVICE_LRJ_PAYER_BLACKLIST:  # comma-separated list
  JARVICE_LRJ_CURRENCY_FMT: "$%.2f" # printf-format, single %f value

  # upstream scheduler pass maximum number of parallel worker threads
  JARVICE_SCHED_PASS_WORKERS: # defaults to 8

  # time budget in seconds alloted to an upstream scheduler pass
  JARVICE_SCHED_PASS_BUDGET:  # defaults to 30

  # grace period to allow newly queued jobs to enqueue downstream before
  # auto-cancellation
  JARVICE_SCHED_PASS_NEW_GRACE_SECS:  # defaults to 30

  # downstream pod scheduler maximum number of parallel worker threads
  JARVICE_POD_SCHED_WORKERS:  # defaults to 8

  ingress:
    class: "traefik"  # "nginx"
    tls:
      # cert-manager must be deployed in order to use certificate issuers
      # issuer.name takes precedence over cluster_issuer.name, do not set both
      cluster_issuer:
        name: # "my-cluster-issuer"
      issuer:
        name: # "letsencrypt-prod" # "letsencrypt-staging" # "selfsigned"
        # An admin email is required when letsencrypt issuer is set. The first
        # JARVICE_MAIL_ADMINS email will be used if issuer.email is not set.
        email: # "admin@my-domain.com"
      # If crt and key values are provided, issuer settings will be ignored
      crt: # base64 encoded.  e.g. Execute: base64 -w 0 <site-domain>.pem
      key: # base64 encoded.  e.g. Execute: base64 -w 0 <site-domain>.key

  # Set to "true" if using SELinux in enforcing mode on hosts targetted for
  # computation, and see SELinux.md for details
  JARVICE_SELINUX_ENFORCING: # "true"

  # uncomment value to relax node weight calculations in order to account
  # for minor inconsequential variance (e.g. when using explicit node selectors
  # any way, such as specific instance types)
  JARVICE_POD_SCHED_LICENSE_PRE: "false"
  JARVICE_POD_SCHED_MULTIPLIERS: # '{"cpu": 0, "memory": 0, "ephemeral-storage": 0, "pods": 0}'

  # Global setting for enabling a secure NetworkPolicy for all JARVICE services
  # The global setting can be overridden within individual services below
  networkPolicy:
    enabled: true

  # Review the following for more information on "skinning" JARVICE with
  # the optional jarvice.settings.configMap:
  # https://github.com/nimbix/jarvice-helm#customize-jarvice-files-via-a-configmap
  settings:
    configMap: jarvice-settings

  # Optionally, provide root certificate for JARVICE pods
  # jarvice.cacert.configMap:
  # TODO docs
  cacert:
    user:
      configMap: # jarvice-cacert
    java:
      configMap: # jarvice-java-cacert

  JARVICE_SYSTEM_NAMESPACE: # auto-detected, should not need to be updated
  JARVICE_JOBS_NAMESPACE: # auto-set, should not need to be updated
  JARVICE_BUILDS_NAMESPACE: # auto-set, should not need to be updated
  JARVICE_PULLS_NAMESPACE: # auto-set, should not need to be updated
  JARVICE_DAEMONSETS_NAMESPACE: # auto-set, should not need to be updated

  # Optionally, override FQDN used by the API
  # JARVICE_API_PUBLIC_URL: # jarvice-api.my-domain.com # set API URL

  # If using an S3-compatible object storage to store complete job output
  # and pod JSON, set ALL of the following mandatory values:
  JARVICE_S3_BUCKET: # bucket to store job output in
  JARVICE_S3_ACCESSKEY: # access key for bucket
  JARVICE_S3_SECRETKEY: # secret access key for bucket

  # the following values are optional (defaults noted)
  JARVICE_S3_REGION: # defaults to None
  JARVICE_S3_PREFIX: "output/" # object name prefix
  JARVICE_S3_ENDPOINTURL: # object store endpoint URL, defaults to AWS

  # the following value should be set to the value needed for the annotation
  # k8s.v1.cni.cncf.io/networks to specify the Multus CNI name for passing in
  # IPoIB networks (needed when using the ibrdma plugin)
  JARVICE_IB_CNI_NETWORKS: # defaults to jarvice-ipoib

  # Optionally, quick enable DaemonSets here.  More details can be found at:
  # https://github.com/nimbix/jarvice-helm#kubernetes-device-plugins
  # https://github.com/nimbix/jarvice-helm#install-recommended-daemonsets
  # If running multiple JARVICE deployments, enable daemonsets for only one.
  daemonsets:
    tolerations: '[{"key": "node-role.jarvice.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "CriticalAddonsOnly", "operator": "Exists"}]'
    nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-compute", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-compute", "operator": "Exists"}]}] }}'
    nodeSelector: # '{"node-role.jarvice.io/jarvice-compute": "true"}'
    images_pull: # Obsoletes cache_pull Daemonset below
      enabled: false
      tolerations: # '[{"key": "node-role.jarvice.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "CriticalAddonsOnly", "operator": "Exists"}]'
      nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-compute", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-compute", "operator": "Exists"}]}] }}'
      nodeSelector: # '{"node-role.jarvice.io/jarvice-compute": "true"}'
      interval: 3600  # Default: 3600 (1 hour)
      images:
        #amd64:
        #  - us-docker.pkg.dev/jarvice/images/app-filemanager:ocpassform
        #  - us-docker.pkg.dev/jarvice/images/ubuntu-desktop:bionic
        #  - us-docker.pkg.dev/jarvice/images/app-openfoam:8
        #arm64:
        #  - us-docker.pkg.dev/jarvice/images/app-filemanager:ocpassform-arm
        #  - us-docker.pkg.dev/jarvice/images/ubuntu-desktop:bionic-arm
        #  - us-docker.pkg.dev/jarvice/images/app-openfoam:8-arm
      #imagePullSecrets:  # additional imagePullSecrets to use
      #  - name: my-image-pull-secret-0
      #  - name: my-image-pull-secret-1
    cache_pull: # DEPRECATED: Please use images_pull DaemonSet above
      enabled: false
      tolerations: # '[{"key": "node-role.jarvice.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "CriticalAddonsOnly", "operator": "Exists"}]'
      nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-compute", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-compute", "operator": "Exists"}]}] }}'
      nodeSelector: # '{"node-role.jarvice.io/jarvice-compute": "true"}'
      image: us-docker.pkg.dev/jarvice/images/jarvice-cache-pull:20201116
      imagePullPolicy: IfNotPresent
    lxcfs:
      enabled: false
      tolerations: # '[{"key": "node-role.jarvice.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "CriticalAddonsOnly", "operator": "Exists"}]'
      nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-compute", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-compute", "operator": "Exists"}]}] }}'
      nodeSelector: # '{"node-role.jarvice.io/jarvice-compute": "true"}'
      image: us-docker.pkg.dev/jarvice/images/lxcfs:3.0.3-4
      imagePullPolicy: IfNotPresent
      env:
        HOST_LXCFS_DIR: /var/lib/lxcfs
        HOST_LXCFS_INSTALL_DIR: /usr/local/lxcfs-daemonset
    disable_hyper_threading:
      enabled: false
      tolerations: #'[{"key": "node-role.jarvice.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "CriticalAddonsOnly", "operator": "Exists"}]'
      nodeAffinity: '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-compute", "operator": "Exists"}, {"key": "kubernetes.io/arch", "operator": "In", "values": ["amd64"]}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-compute", "operator": "Exists"}, {"key": "kubernetes.io/arch", "operator": "In", "values": ["amd64"]}]}] }}'
      nodeSelector: # '{"node-role.jarvice.io/jarvice-compute": "true", "kubernetes.io/arch": "amd64"}'
      pauseImage: gcr.io/google-containers/pause:3.2
      image: us-docker.pkg.dev/jarvice/images/busybox:latest
      imagePullPolicy: IfNotPresent
    node_init:
      enabled: false
      tolerations: # '[{"key": "node-role.jarvice.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "CriticalAddonsOnly", "operator": "Exists"}]'
      nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-compute", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-compute", "operator": "Exists"}]}] }}'
      nodeSelector: # '{"node-role.jarvice.io/jarvice-compute": "true"}'
      pauseImage: gcr.io/google-containers/pause:3.2
      image: us-docker.pkg.dev/jarvice/images/busybox:latest
      imagePullPolicy: IfNotPresent
      env:
        COMMAND: |
            echo "Disabling kernel check for hung tasks..."
            echo 0 > /proc/sys/kernel/hung_task_timeout_secs || /bin/true
            echo "Disabling kernel check for hung tasks...done."
    nvidia:
      enabled: false
      tolerations: # '[{"key": "node-role.jarvice.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "CriticalAddonsOnly", "operator": "Exists"}]'
      nodeAffinity: '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-compute", "operator": "Exists"}, {"key": "kubernetes.io/arch", "operator": "In", "values": ["amd64", "ppc64le"]}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-compute", "operator": "Exists"}, {"key": "kubernetes.io/arch", "operator": "In", "values": ["amd64", "ppc64le"]}]}] }}'
      nodeSelector: # '{"node-role.jarvice.io/jarvice-compute": "true", "kubernetes.io/arch": "amd64"}'
      image: us-docker.pkg.dev/jarvice/images/nvidia-k8s-device-plugin:1.11
      imagePullPolicy: IfNotPresent
    nvidia_install:
      enabled: false
      tolerations: # '[{"key": "node-role.jarvice.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "CriticalAddonsOnly", "operator": "Exists"}]'
      nodeAffinity: '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-compute", "operator": "Exists"}, {"key": "kubernetes.io/arch", "operator": "In", "values": ["amd64", "ppc64le"]}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-compute", "operator": "Exists"}, {"key": "kubernetes.io/arch", "operator": "In", "values": ["amd64", "ppc64le"]}]}] }}'
      nodeSelector: # '{"node-role.jarvice.io/jarvice-compute": "true", "kubernetes.io/arch": "amd64"}'
      pauseImage: gcr.io/google-containers/pause:3.2
      image: us-docker.pkg.dev/jarvice/images/busybox:latest
      imagePullPolicy: IfNotPresent
      env:
        NVIDIA_DRIVER_VERSION: 450.102.04-1
    xilinx_fpga:
      enabled: false
      tolerations: # '[{"key": "node-role.jarvice.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "CriticalAddonsOnly", "operator": "Exists"}]'
      # Xilinx FPGA only supports amd64 arch
      nodeAffinity: '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-compute", "operator": "Exists"}, {"key": "kubernetes.io/arch", "operator": "In", "values": ["amd64"]}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-compute", "operator": "Exists"}, {"key": "kubernetes.io/arch", "operator": "In", "values": ["amd64"]}]}] }}'
      nodeSelector: # '{"node-role.jarvice.io/jarvice-compute": "true", "kubernetes.io/arch": "amd64"}'
      image: us-docker.pkg.dev/jarvice/images/xilinx_k8s_fpga_plugin:2020.11.24
      imagePullPolicy: IfNotPresent
    rdma:
      enabled: false
      tolerations: # '[{"key": "node-role.jarvice.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "CriticalAddonsOnly", "operator": "Exists"}, {"key": "jarvice.com/rdma", "operator": "Exists",  "effect": "NoSchedule"}]'
      nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-compute", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-compute", "operator": "Exists"}]}] }}'
      nodeSelector: # '{"node-role.jarvice.io/jarvice-compute": "true"}'
      image: us-docker.pkg.dev/jarvice/images/k8s-rdma-device:1.0.3
      imagePullPolicy: IfNotPresent
    dri_optional:
      enabled: true
      tolerations: # '[{"key": "node-role.jarvice.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "CriticalAddonsOnly", "operator": "Exists"}]'
      nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-compute", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-compute", "operator": "Exists"}]}] }}'
      nodeSelector: # '{"node-role.jarvice.io/jarvice-compute": "true"}'
      initImage: us-docker.pkg.dev/jarvice/images/busybox:latest
      image: us-docker.pkg.dev/jarvice/images/k8s-dri-optional-device:1.0.2
      imagePullPolicy: IfNotPresent
      env:
        DRI_INIT_DELAY: 1
        DRI_DEFAULT_CAPACITY: 128
    flex_volume_plugin_nfs_nolock_install:
      enabled: true
      tolerations: '[{"key": "node-role.jarvice.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.jarvice.io/jarvice-system", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-system", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.jarvice.io/jarvice-storage", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-storage", "effect": "NoSchedule", "operator": "Exists"}]'
      nodeAffinity: '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-compute", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-compute", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-system", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-system", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-storage", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-storage", "operator": "Exists"}]}] }}'
      nodeSelector: # '{"node-role.jarvice.io/jarvice-compute": "true", "kubernetes.io/arch": "amd64"}'
      pauseImage: gcr.io/google-containers/pause:3.2
      image: us-docker.pkg.dev/jarvice/images/busybox:latest
      imagePullPolicy: IfNotPresent
      env:
        KUBELET_PLUGIN_DIR: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
    # jarvice_registry_proxy DaemonSet is enabled when the
    # jarvice_registry_proxy Deployment is enabled below
    jarvice_registry_proxy:
      tolerations: '[{"key": "node-role.jarvice.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.jarvice.io/jarvice-system", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-system", "effect": "NoSchedule", "operator": "Exists"}, {"key": "CriticalAddonsOnly", "operator": "Exists"}]'
      nodeAffinity: '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-compute", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-compute", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-system", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-system", "operator": "Exists"}]}] }}'
      nodeSelector: # '{"node-role.jarvice.io/jarvice-compute": "true"}' # '{"node-role.jarvice.io/jarvice-system": "true"}'
      pauseImage: gcr.io/google-containers/pause:3.2
      image: us-docker.pkg.dev/jarvice/images/busybox:latest
      imagePullPolicy: IfNotPresent
      env:
        DOCKER_CERTS_DIR: /etc/docker/certs.d


# Database server previously set up?  Set enabled to false.
jarvice_db: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  enabled: true
  replicaCount: 1
  resources:
    requests:
      cpu: 1
      memory: 2Gi
    limits:
      cpu: 4
      memory: 2Gi
  readinessProbe:
    initialDelaySeconds: 5
    timeoutSeconds: 2
  livenessProbe:
    initialDelaySeconds: 30
    timeoutSeconds: 5
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-db", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-db", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-db", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-db": "true"}'
  networkPolicy:
    enabled: # Inherits from jarvice.networkPolicy.enabled if unset
  image: us-docker.pkg.dev/jarvice/images/mariadb:10.5
  imagePullPolicy: IfNotPresent
  persistence:
    enabled: false
    # Set to "keep" to prevent removal of jarvice-db-pvc on helm delete
    resourcePolicy: ""  # "keep"
    # Use empty existingClaimName for dynamic provisioning via storageClass
    existingClaimName: # "jarvice-db-pvc"
    # storageClass: "-"  # "-" uses cluster's default StorageClass/provisioner
    storageClass: "jarvice-db"
    accessMode: ReadWriteOnce
    size: 8Gi
  securityContext:
    enabled: false  # Enable when PersistentVolume is root squashed
    fsGroup: 999
    runAsUser: 999
  # MYSQL_ROOT_PASSWORD inherits from jarvice.JARVICE_DBPASSWD if unset
  # MYSQL_USER only inherits from jarvice.JARVICE_DBUSER if
  #     jarvice.JARVICE_DBUSER != 'root'
  # MYSQL_PASSWORD is only used if MYSQL_USER is set or
  #     jarvice.JARVICE_DBUSER != 'root'
  # MYSQL_PASSWORD inherits from jarvice.JARVICE_DBPASSWD if unset
  env:
    MYSQL_ROOT_PASSWORD: # Pass1234
    MYSQL_USER: # nimbix # optional, additional superuser
    MYSQL_PASSWORD: # Pass1234

# Enable to use a kubernetes CronJob to regularly dump the JARVICE database
jarvice_db_dump: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  enabled: false
  schedule: "0 4 * * *"
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1
  deleteOldBackups:
    enabled: true
    keep: 14  # Number of dumps to keep
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-dal", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-dal", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-dal", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-dal": "true"}'
  persistence:
    # Set to "keep" to prevent removal of jarvice-db-dump-pvc on helm delete
    resourcePolicy: ""  # "keep"
    # Use empty existingClaimName for dynamic provisioning via storageClass
    existingClaimName: # "jarvice-db-dump-pvc"
    # storageClass: "-"  # "-" uses cluster's default StorageClass/provisioner
    storageClass: "jarvice-db-dump"
    accessMode: ReadWriteOnce
    size: 50Gi
  securityContext:
    enabled: false  # Enable and set to user and group to use for dump
    fsGroup: 999
    runAsUser: 999

# jarvice_smtpd may be disabled when not set for jarvice.JARVICE_MAIL_SERVER
jarvice_smtpd: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  enabled: true
  replicaCount: 2
  # PodDisruptionBudget default requires 25% minimum of pods must be running
  pdb:
    minAvailable: "25%"
  # antiAffinity default of "soft" prefers that pods run on diff nodes.
  # Set to "hard" to require pods to run on diff nodes.
  antiAffinity: "soft"
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
  readinessProbe:
    initialDelaySeconds: 5
    timeoutSeconds: 2
  livenessProbe:
    initialDelaySeconds: 30
    timeoutSeconds: 5
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-smtpd", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-smtpd", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-smtp", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-smtpd": "true"}'
  networkPolicy:
    enabled: # Inherits from jarvice.networkPolicy.enabled if unset
  image: us-docker.pkg.dev/jarvice/images/postfix:3.11_3.4.12-r0
  imagePullPolicy: IfNotPresent

# Web service to map a username to full Linux identity based on inspection
# of a shared filesystem:  https://github.com/nimbix/idmapper
# Enable by setting jarvice_idmapper.enabled to true.  Then, configure shared
# filesystem settings under jarvice_idmapper.filesystem and jarvice_idmapper.env
jarvice_idmapper: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  enabled: false
  replicaCount: 2
  # PodDisruptionBudget default requires 25% minimum of pods must be running
  pdb:
    minAvailable: "25%"
  # antiAffinity default of "soft" prefers that pods run on diff nodes.
  # Set to "hard" to require pods to run on diff nodes.
  antiAffinity: "soft"
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
  readinessProbe:
    initialDelaySeconds: 3
    periodSeconds: 15
    timeoutSeconds: 1
    successThreshold: 1
    failureThreshold: 3
  livenessProbe:
    initialDelaySeconds: 3
    periodSeconds: 15
    timeoutSeconds: 1
    successThreshold: 1
    failureThreshold: 2
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-idmapper", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-idmapper", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-idmapper", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-idmapper": "true"}'
  networkPolicy:
    enabled: # Inherits from jarvice.networkPolicy.enabled if unset
  image: us-docker.pkg.dev/jarvice/images/idmapper:20201116
  imagePullPolicy: IfNotPresent
  # Shared filesystem settings.  Defaults to hostPath if NFS server is not set
  filesystem:
    path: /home
    server: # nfs.my-domain.com
  # Visit https://github.com/nimbix/idmapper for environment variable details
  env:
    HOMEPATH: "/home/%u/"
    UPNPATH: "false"

# Memcached server previously set up?  Set jarvice_memcached.enabled to false.
# Then, set JARVICE_PORTAL_MEMCACHED_LOCATIONS below in jarvice_mc_portal env.
jarvice_memcached: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  enabled: true
  replicaCount: 3
  # PodDisruptionBudget default requires 2 minimum pods must be running
  pdb:
    minAvailable: 2
  # antiAffinity default of "soft" prefers that pods run on diff nodes.
  # Set to "hard" to require pods to run on diff nodes.
  antiAffinity: "soft"
  resources:
    limits:
      cpu: 250m
      memory: 512Mi
  readinessProbe:
    initialDelaySeconds: 5
    timeoutSeconds: 1
  livenessProbe:
    initialDelaySeconds: 30
    timeoutSeconds: 5
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-memcached", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-memcached", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-memcached", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-memcached": "true"}'
  networkPolicy:
    enabled: # Inherits from jarvice.networkPolicy.enabled if unset
  image: us-docker.pkg.dev/jarvice/images/memcached:1.5
  imagePullPolicy: IfNotPresent
  maxItemMemory: 64
  verbosity: v
  extendedOptions: modern

# cert-manager must be deployed before enabling jarvice-registry-proxy
jarvice_registry_proxy:
  enabled: false
  nodePort: 32443
  # replicaCount>1 requires ReadWriteMany storageClass/accessMode persistence
  replicaCount: 1
  # PodDisruptionBudget default requires 25% minimum of pods must be running
  pdb:
    minAvailable: "25%"
  # antiAffinity default of "soft" prefers that pods run on diff nodes.
  # Set to "hard" to require pods to run on diff nodes.
  antiAffinity: "soft"
  resources:
    limits:
      cpu: 1
      memory: 512Mi
  readinessProbe:
    initialDelaySeconds: 5
    timeoutSeconds: 1
  livenessProbe:
    initialDelaySeconds: 30
    timeoutSeconds: 5
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-registry-proxy", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-registry-proxy", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-registry-proxy", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-registry-proxy": "true"}'
  image: us-docker.pkg.dev/jarvice/images/registry:2
  imagePullPolicy: IfNotPresent
  persistence:
    enabled: false
    # Set to "keep" to prevent jarvice-registry-proxy-pvc removal on helm delete
    resourcePolicy: ""  # "keep"
    # Use empty existingClaimName for dynamic provisioning via storageClass
    existingClaimName: # "jarvice-registry-proxy-pvc"
    # storageClass: "-"  # "-" uses cluster's default StorageClass/provisioner
    storageClass: "jarvice-registry-proxy"
    accessMode: ReadWriteOnce
    size: 500Gi
  env:
    # jarvice.JARVICE_SYSTEM_REGISTRY and jarvice.imagePullSecret will be used
    # to set the values for REGISTRY_PROXY_* unless overridden here
    REGISTRY_PROXY_REMOTEURL: # us-docker.pkg.dev  # (auto-prefixed with "https://")
    REGISTRY_PROXY_USERNAME: # _json_key
    REGISTRY_PROXY_PASSWORD: # base64 encoded: cat key.json | base64 -w 0

# Enable to use a kubernetes CronJob to schedule image garbage collection
jarvice_registry_proxy_gc: # N/A if jarvice_registry_proxy.enabled is false
  enabled: false
  schedule: "0 4 * * *"
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-registry-proxy", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-registry-proxy", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-registry-proxy", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-registry-proxy": "true"}'
  image: us-docker.pkg.dev/jarvice/images/jarvice-kubectl:v1.21.7
  imagePullPolicy: IfNotPresent
  env:
    IMAGE_LAST_ACCESS_SECONDS: 2592000  # Default: 2592000 (30 days)

jarvice_dal: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  enabled: true
  replicaCount: 2
  replicaCountMax: 6
  # HorizontalPodAutoscaler is enabled when replicaCountMax > replicaCount
  autoscaling:
    metrics:
      - type: Resource
        resource:
          name: cpu
          target:
            type: Utilization
            averageUtilization: 60
      - type: Resource
        resource:
          name: memory
          target:
            type: Utilization
            averageUtilization: 60
  # PodDisruptionBudget default requires 25% minimum of pods must be running
  pdb:
    minAvailable: "25%"
  # antiAffinity default of "soft" prefers that pods run on diff nodes.
  # Set to "hard" to require pods to run on diff nodes.
  antiAffinity: "soft"
  resources:
    requests:
      cpu: 2
      memory: 8Gi
    limits:
      cpu: 8
      memory: 8Gi
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 30
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 60
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  hostNetwork: false
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-dal", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-dal", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-dal", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-dal": "true"}'
  networkPolicy:
    enabled: # Inherits from jarvice.networkPolicy.enabled if unset
  # jarvice.settings.configMap takes precedence over environment settings
  # for JARVICE_CFG_NETWORK
  # JARVICE_SITE_DBHOST inherits from jarvice.JARVICE_DBHOST if unset
  # JARVICE_SITE_DBPASSWD inherits from jarvice.JARVICE_DBPASSWD if unset
  # JARVICE_SITE_DBUSER inherits from jarvice.JARVICE_DBUSER if unset
  env:
    JARVICE_SITE_DBHOST: # jarvice-db
    JARVICE_SITE_DBUSER: # root
    JARVICE_SITE_DBPASSWD: # Pass1234
    JARVICE_ROOT_USER_CREATE: False
    JARVICE_ROOT_USER_PASSWD: Pass1234
    JARVICE_ROOT_USER_EMAIL: root@localhost
    JARVICE_USER_REGISTRY_VERIFY: False
    JARVICE_ROOT_USER_VAULT: # default-BLOCK-1GB
    JARVICE_ROOT_USER_VAULT_SIZE: # 1
    JARVICE_MACHINES_ADD: '[{"mc_name":"n0", "mc_description":"2 core, 16GB RAM (CPU only)", "mc_cores":"2", "mc_slots":"2", "mc_gpus":"0", "mc_ram":"16", "mc_swap":"8", "mc_scratch":"64", "mc_devices":"", "mc_properties":"", "mc_slave_properties":"", "mc_slave_gpus":"0", "mc_slave_ram":"16", "mc_scale_min":"1", "mc_scale_max":"1", "mc_scale_select":"", "mc_lesser":"1", "mc_price":"0.00", "mc_priority":"0", "mc_privs":"", "mc_arch":"x86_64"}, {"mc_name":"n1", "mc_description":"4 core, 32GB RAM (CPU Only)", "mc_cores":"4", "mc_slots":"4", "mc_gpus":"0", "mc_ram":"32", "mc_swap":"16", "mc_scratch":"100", "mc_devices":"", "mc_properties":"", "mc_slave_properties":"", "mc_slave_gpus":"0", "mc_slave_ram":"32", "mc_scale_min":"1", "mc_scale_max":"1", "mc_scale_select":"", "mc_lesser":"1", "mc_price":"0.00", "mc_priority":"0", "mc_privs":"", "mc_arch":"x86_64"}, {"mc_name":"n3", "mc_description":"16 core, 128GB RAM (CPU Only)", "mc_cores":"16", "mc_slots":"16", "mc_gpus":"0", "mc_ram":"128", "mc_swap":"64", "mc_scratch":"500", "mc_devices":"", "mc_properties":"", "mc_slave_properties":"", "mc_slave_gpus":"0", "mc_slave_ram":"128", "mc_scale_min":"1", "mc_scale_max":"256", "mc_scale_select":"", "mc_lesser":"1", "mc_price":"0.00", "mc_priority":"0", "mc_privs":"", "mc_arch":"x86_64"}]'
    JARVICE_CFG_NETWORK: |
        [global]
        netmask: 255.255.0.0
        gateway: 172.17.0.1
        dns: 8.8.8.8,8.8.4.4
        search: localdomain,dev.nimbix.net,nimbix.net
        linuxbr: docker0
        naelimit: 0
        nae_nfs_bind: 172.17.0.0/16
        [floating]
        start: 172.17.0.100
        end: 172.17.0.255
        [nat]
        [static]
        [fqdns]
        [naelimits]
    JARVICE_NODE_ENV: production

jarvice_scheduler: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  enabled: true
  replicaCount: 2
  # PodDisruptionBudget default requires 25% minimum of pods must be running
  pdb:
    minAvailable: "25%"
  # antiAffinity default of "soft" prefers that pods run on diff nodes.
  # Set to "hard" to require pods to run on diff nodes.
  antiAffinity: "soft"
  resources:
    requests:
      cpu: 1
      memory: 2Gi
    limits:
      cpu: 4
      memory: 8Gi
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 30
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 60
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-scheduler", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-scheduler", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-scheduler", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-scheduler": "true"}'
  networkPolicy:
    enabled: # Inherits from jarvice.networkPolicy.enabled if unset
  env:
    JARVICE_SCHED_PASS_INTERVAL: 5
    JARVICE_SCHED_CLUSTERS_TIMEOUT: 20

jarvice_sched_pass: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  enabled: true
  # PodDisruptionBudget default requires 25% minimum of pods must be running
  pdb:
    minAvailable: "25%"
  # antiAffinity default of "soft" prefers that pods run on diff nodes.
  # Set to "hard" to require pods to run on diff nodes.
  antiAffinity: "soft"
  resources:
    requests:
      cpu: 2
      memory: 2Gi
    limits:
      cpu: 8
      memory: 8Gi
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 30
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 60
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-sched-pass", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-sched-pass", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-sched-pass", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-sched-pass": "true"}'
  env:
    JARVICE_SCHED_PASS_INTERVAL: 5
    JARVICE_SCHED_CLUSTERS_TIMEOUT: 20

jarvice_k8s_scheduler:
  enabled: true
  replicaCount: 2
  # PodDisruptionBudget default requires 25% minimum of pods must be running
  pdb:
    minAvailable: "25%"
  # antiAffinity default of "soft" prefers that pods run on diff nodes.
  # Set to "hard" to require pods to run on diff nodes.
  antiAffinity: "soft"
  # loadBalancerIP and ingressHost are only applicable when
  # jarvice.JARVICE_CLUSTER_TYPE is set to "downstream"
  loadBalancerIP:
  ingressHost: # jarvice-k8s-scheduler.my-domain.com
  resources:
    requests:
      cpu: 1
      memory: 2Gi
    limits:
      cpu: 4
      memory: 8Gi
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 30
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 60
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-k8s-scheduler", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-k8s-scheduler", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-k8s-scheduler", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-k8s-scheduler": "true"}'
  networkPolicy:
    enabled: # Inherits from jarvice.networkPolicy.enabled if unset
  env:
    JARVICE_UNFS_REQUEST_MEM: 1Gi
    JARVICE_UNFS_REQUEST_CPU: 1
    JARVICE_UNFS_EXPIRE_SECS: 90
    JARVICE_UNFS_NODE_SELECTOR: # '{"node-role.jarvice.io/jarvice-storage": "true"}' # '{"node-role.kubernetes.io/jarvice-storage": "true"}'
    JARVICE_UNFS3_IMAGE: us-docker.pkg.dev/jarvice/images/unfs3:20190318-1 # change if mirroring locally
    JARVICE_PVCLS_IMAGE: us-docker.pkg.dev/jarvice/images/alpine:3.8 # change if mirroring locally
    JARVICE_SCHED_JOB_UID:  # set to numeric value to override UID for jobs
    JARVICE_SCHED_JOB_GID:  # set to numeric value to override GID for jobs

jarvice_slurm_scheduler:
  enabled: false
  networkPolicy:
    enabled: false
  replicaCount: 2
  # PodDisruptionBudget default requires 25% minimum of pods must be running
  pdb:
    minAvailable: "25%"
  # antiAffinity default of "soft" prefers that pods run on diff nodes.
  # Set to "hard" to require pods to run on diff nodes.
  antiAffinity: "soft"
  resources:
    requests:
      cpu: 1
      memory: 2Gi
    limits:
      cpu: 4
      memory: 8Gi
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 30
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 60
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-slurm-scheduler", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-slurm-scheduler", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-slurm-scheduler", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-slurm-scheduler": "true"}'
  env:
    JARVICE_SLURM_CLUSTER_PORT: 22   # slurm headnode ssh port
    JARVICE_SLURM_SCHED_LOGLEVEL: 30
    JARVICE_SLURM_OVERLAY_SIZE: 640  # minimum 640MB recommended
    JARVICE_SLURM_HTTPS_PROXY: ""
    JARVICE_SLURM_HTTP_PROXY: ""
    JARVICE_SLURM_NO_PROXY: ""
    JARVICE_SINGULARITY_VERBOSE: false
    JARVICE_SINGULARITY_TMPDIR: ""
  # define each slurm scheduler
  schedulers:
  - name: default
    env:
      JARVICE_SLURM_CLUSTER_ADDR: # address for slurm headnode
      # uncomment to override
      # JARVICE_SLURM_CLUSTER_PORT: 22   # slurm headnode ssh port
      # JARVICE_SLURM_SCHED_LOGLEVEL: 30
      # JARVICE_SLURM_OVERLAY_SIZE: 640
    sshConf:
      user: # user to ssh into slurm headnode (e.g. nimbix)
      pkey: # base64 encoded private ssh key for JXE slurm scheduler service. Add public key to slurm headnode.
      # Alternatively, define secret
      # secret.Data["user"]: # user to ssh into slurm headnode (e.g. nimbix)
      # secret.Data["pkey"]: # base64 encoded private ssh key for JXE slurm scheduler service. Add public key to slurm headnode.
      secret:
    # local override values
    # replicaCount: 2
    # PodDisruptionBudget default requires 25% minimum of pods must be running
    # pdb:
    #   minAvailable: "25%"
    # antiAffinity default of "soft" prefers that pods run on diff nodes.
    # Set to "hard" to require pods to run on diff nodes.
    # antiAffinity: "soft"
    # resources:
    #   requests:
    #     cpu: 1
    #     memory: 2Gi
    #   limits:
    #     cpu: 4
    #     memory: 8Gi
    # readinessProbe:
    #   initialDelaySeconds: 5
    #   periodSeconds: 30
    #   timeoutSeconds: 3
    #   successThreshold: 1
    #   failureThreshold: 3
    # livenessProbe:
    #   initialDelaySeconds: 30
    #   periodSeconds: 60
    #   timeoutSeconds: 3
    #   successThreshold: 1
    #   failureThreshold: 3
    # tolerations: # '[{"key": "node-role.jarvice.io/jarvice-slurm-scheduler", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-slurm-scheduler", "effect": "NoSchedule", "operator": "Exists"}]'
    # nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-slurm-scheduler", "operator": "Exists"}]}] }}'
    # nodeSelector: # '{"node-role.jarvice.io/jarvice-slurm-scheduler": "true"}'
  # add additional slurm schedulers here
  # - name: # name for slurm-scheduler deployment (must be unique)
  #     env:
  #     JARVICE_SLURM_CLUSTER_ADDR: # address for slurm headnode
  #     # uncomment to override
  #     # JARVICE_SLURM_CLUSTER_PORT: 22   # slurm headnode ssh port
  #     # JARVICE_SLURM_SCHED_LOGLEVEL: 30
  #     # JARVICE_SLURM_OVERLAY_SIZE: 128
  #   sshConf:
  #     user: # user to ssh into slurm headnode (e.g. nimbix)
  #     pkey: # base64 encoded private ssh key for JXE slurm scheduler service. Add public key to slurm headnode.
  #     # Alternatively, define secret
  #     # secret.Data["user"]: # user to ssh into slurm headnode (e.g. nimbix)
  #     # secret.Data["pkey"]: # base64 encoded private ssh key for JXE slurm scheduler service. Add public key to slurm headnode.
  #     secret:

jarvice_pod_scheduler:
  enabled: true
  resources:
    requests:
      cpu: 2
      memory: 2Gi
    limits:
      cpu: 4
      memory: 8Gi
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 30
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 60
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-pod-scheduler", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-pod-scheduler", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-pod-scheduler", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-pod-scheduler": "true"}'
  env:
    JARVICE_POD_SCHED_NAME:  # auto-set, should not need to be updated

# jarvice-license-manager runs on amd64 nodes only. In a multi-arch cluster, it
# may be necessary to set tolerations, nodeAffinity, and/or nodeSelector.
# Also, create/update jarvice-license-manager ConfigMap w/ servers.json data
# Uses "user:password" pair set in jarvice.JARVICE_LICENSE_MANAGER_KEY
jarvice_license_manager: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  enabled: false
  loadBalancerIP:
  ingressHost: # jarvice-license-manager.my-domain.com
  resources:
    limits:
      cpu: 1
      memory: 2Gi
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 30
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 60
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-license-manager", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-license-manager", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "kubernetes.io/arch", "operator": "In", "values": ["amd64"]}]}] }}'  # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-license-manager", "operator": "Exists"}, {"key": "kubernetes.io/arch", "operator": "In", "values": ["amd64"]}]}] }}'
  nodeSelector: # '{"kubernetes.io/arch": "amd64"}'  # '{"node-role.jarvice.io/jarvice-license-manager": "true", "kubernetes.io/arch": "amd64"}'
  networkPolicy:
    enabled: # Inherits from jarvice.networkPolicy.enabled if unset
  env:
    JARVICE_HOSTALIASES: # '[ {"ip": "10.20.0.1", "hostnames": ["hostname-1a"]}, {"ip": "10.20.0.2", "hostnames": ["hostname-2a", "hostname-2b"]} ]'
    JARVICE_LMSTAT_INTERVAL: 60
    JARVICE_S3_BUCKET:
    JARVICE_S3_ACCESSKEY:
    JARVICE_S3_SECRETKEY:
    JARVICE_S3_ENDPOINTURL: # https://s3.my-domain.com

jarvice_api: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  enabled: true
  replicaCount: 2
  replicaCountMax: 6
  # HorizontalPodAutoscaler is enabled when replicaCountMax > replicaCount
  autoscaling:
    metrics:
      - type: Resource
        resource:
          name: cpu
          target:
            type: Utilization
            averageUtilization: 60
      - type: Resource
        resource:
          name: memory
          target:
            type: Utilization
            averageUtilization: 60
  # PodDisruptionBudget default requires 25% minimum of pods must be running
  pdb:
    minAvailable: "25%"
  # antiAffinity default of "soft" prefers that pods run on diff nodes.
  # Set to "hard" to require pods to run on diff nodes.
  antiAffinity: "soft"
  loadBalancerIP:
  ingressHost: # jarvice-api.my-domain.com
  ingressPath: "/"  # Valid values are "/" (default) or "/api"
  ingressAnnotations: # '{"nginx.org/client-max-body-size": "0", "nginx.org/proxy-read-timeout": "3600", "nginx.org/proxy-send-timeout": "3600"}'
  resources:
    limits:
      cpu: 1
      memory: 1Gi
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 30
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 60
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-api", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-api", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-api", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-api": "true"}'
  env:
    JARVICE_API_POOL_SIZE: 4
  networkPolicy:
    enabled: # Inherits from jarvice.networkPolicy.enabled if unset

jarvice_dockerpull: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-dockerpull", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-dockerpull", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-dockerpull", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-dockerpull": "true"}'

jarvice_dockerbuild: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  resources:
    requests:
      cpu: 1
      memory: 2Gi
    limits:
      cpu: 3
      memory: 3Gi
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-dockerbuild", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-dockerbuild", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-dockerbuild", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-dockerbuild": "true"}'
  persistence:  # Enable to execute builds on dynamically provisioned PVCs
    enabled: false
    # storageClass: "-"  # "-" uses cluster's default StorageClass/provisioner
    storageClass: "jarvice-dockerbuild"
    size: 300Gi

# Enable to use a kubernetes CronJob to garbage collect dockerbuild PVCs
# N/A if jarvice_dockerbuild.persistence.enabled is false
jarvice_dockerbuild_pvc_gc:
  enabled: false
  schedule: "*/1 * * * *"
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-dockerbuild-pvc-gc", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-dockerbuild-pvc-gc", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-dockerbuild-pvc-gc", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-dockerbuild-pvc-gc": "true"}'
  image: us-docker.pkg.dev/jarvice/images/jarvice-kubectl:v1.21.7
  imagePullPolicy: IfNotPresent
  env:
    JARVICE_BUILD_PVC_KEEP_SUCCESSFUL: 3600  # Default: 3600 (1 hour)
    JARVICE_BUILD_PVC_KEEP_ABORTED: 7200  # Default: 7200 (2 hours)
    JARVICE_BUILD_PVC_KEEP_FAILED: 14400  # Default: 14400 (4 hours)

# Enable to use a kubernetes CronJob to pull/refresh app images
jarvice_images_pull:
  enabled: false
  schedule: "0 4 * * *"
  scheduleNow: false  # Immediately schedule images pull job on install/upgrade
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-images-pull", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-images-pull", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-images-pull", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-images-pull": "true"}'
  images:
    #amd64:
    #  - us-docker.pkg.dev/jarvice/images/app-filemanager:ocpassform
    #  - us-docker.pkg.dev/jarvice/images/ubuntu-desktop:bionic
    #  - us-docker.pkg.dev/jarvice/images/app-openfoam:8
  #imagePullSecrets:  # additional imagePullSecrets to use
  #  - name: my-image-pull-secret-0
  #  - name: my-image-pull-secret-1

jarvice_appsync: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  enabled: true
  replicaCount: 1
  resources:
    limits:
      cpu: 250m
      memory: 1Gi
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 30
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 60
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-appsync", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-appsync", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-appsync", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-appsync": "true"}'
  # If JARVICE_SYSTEM_REGISTRY and/or JARVICE_SYSTEM_REPO_BASE are not set in
  # jarvice_appsync.env, they will be set via the global jarvice stanza above.
  env:
    JARVICE_SYSTEM_REGISTRY: # us-docker.pkg.dev
    JARVICE_SYSTEM_REPO_BASE: jarvice-apps
    JARVICE_APPSYNC_INTERVAL: 3600

jarvice_mc_portal: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  enabled: true
  replicaCount: 2
  replicaCountMax: 6
  # HorizontalPodAutoscaler is enabled when replicaCountMax > replicaCount
  autoscaling:
    metrics:
      - type: Resource
        resource:
          name: cpu
          target:
            type: Utilization
            averageUtilization: 60
      - type: Resource
        resource:
          name: memory
          target:
            type: Utilization
            averageUtilization: 60
  # PodDisruptionBudget default requires 25% minimum of pods must be running
  pdb:
    minAvailable: "25%"
  # antiAffinity default of "soft" prefers that pods run on diff nodes.
  # Set to "hard" to require pods to run on diff nodes.
  antiAffinity: "soft"
  loadBalancerIP:
  ingressHost: # jarvice.my-domain.com
  ingressPath: "/"  # Valid values are "/" (default) or "/portal"
  ingressAnnotations: # '{"nginx.org/client-max-body-size": "0", "nginx.org/proxy-read-timeout": "3600", "nginx.org/proxy-send-timeout": "3600"}'
  resources:
    limits:
      cpu: 1
      memory: 2Gi
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 30
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 60
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-mc-portal", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-mc-portal", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-mc-portal", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-mc-portal": "true"}'
  networkPolicy:
    enabled: # Inherits from jarvice.networkPolicy.enabled if unset
  # JARVICE_PORTAL_DBHOST inherits from jarvice.JARVICE_DBHOST if unset
  # JARVICE_PORTAL_DBPASSWD inherits from jarvice.JARVICE_DBPASSWD if unset
  # JARVICE_PORTAL_DBUSER inherits from jarvice.JARVICE_DBUSER if unset
  # JARVICE_PORTAL_WEB_HOST inherits from jarvice_mc_portal.ingressHost/jarvice_mc_portal.ingressPath if unset
  env:
    JARVICE_USER_DEFAULT_ENABLED: True
    JARVICE_USER_DEFAULT_DEVELOPER: True
    JARVICE_PORTAL_JOB_TERMINATE_LIMIT: 100
    JARVICE_PORTAL_GSS_REALM:
    JARVICE_PORTAL_GSS_DOMAIN:
    JARVICE_PORTAL_GSS_LOG: # "debug"
    JARVICE_PORTAL_WEB_HOST: # https://<jarvice_mc_portal.ingressHost><jarvice_mc_portal.ingressPath>
    # If null, JARVICE_PORTAL_MEMCACHED_LOCATIONS is auto-generated based on
    # jarvice_memcached.enabled/jarvice_memcached.replicaCount
    JARVICE_PORTAL_MEMCACHED_LOCATIONS: # jarvice-memcached-0.jarvice-memcached:11211,jarvice-memcached-1.jarvice-memcached:11211,jarvice-memcached-2.jarvice-memcached:11211
    JARVICE_PORTAL_APP_OWNERS:
    JARVICE_PORTAL_DB: nimbix_portal_ng
    JARVICE_PORTAL_DBHOST: # jarvice-db
    JARVICE_PORTAL_DBUSER: # root
    JARVICE_PORTAL_DBPASSWD: # Pass1234
    # If a non-empty string is passed, the MC portal will not warn about the use of API key related substitutions
    JARVICE_DISABLE_API_SUBST_WARNING: # ""
    # If a non-empty string is passed, the MC portal will use this URL for build and pull web links shown to the user
    JARVICE_API_PUBLIC_URL: # https://<jarvice_api.ingressHost><jarvice_api.ingressPath>

jarvice_bird: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  enabled: false
  replicaCount: 1
  replicaCountMax: 1
  # HorizontalPodAutoscaler is enabled when replicaCountMax > replicaCount
  autoscaling:
    metrics:
      - type: Resource
        resource:
          name: cpu
          target:
            type: Utilization
            averageUtilization: 60
      - type: Resource
        resource:
          name: memory
          target:
            type: Utilization
            averageUtilization: 60
  # PodDisruptionBudget default requires 25% minimum of pods must be running
  pdb:
    minAvailable: "25%"
  # antiAffinity default of "soft" prefers that pods run on diff nodes.
  # Set to "hard" to require pods to run on diff nodes.
  antiAffinity: "soft"
  conf:
    configMap: # jarvice-bird-config
  nginx:
    configMap: # jarvice-bird-nginx-config
  preset:
    configMap: # jarvice-bird-user-preset
  env:
    KEYCLOAK_URL: # keycloak.my-domain.com/auth
    KEYCLOAK_ID: jarvice
    KEYCLOAK_REALM: jarvice
    JARVICE_KEYCLOAK_ADMIN_USER: jarvice
    JARVICE_KEYCLOAK_ADMIN_PASS: Pass1234
    JARVICE_USER_DEFAULT_ENABLED: True
    JARVICE_USER_DEFAULT_DEVELOPER: True
    JARVICE_PORTAL_JOB_TERMINATE_LIMIT: 100
    JARVICE_PORTAL_GSS_REALM:
    JARVICE_PORTAL_GSS_DOMAIN:
    JARVICE_PORTAL_GSS_LOG: # "debug"
    JARVICE_PORTAL_WEB_HOST: # https://<jarvice_bird_portal.ingressHost><jarvice_bird_portal.ingressPath>/portal
    # If null, JARVICE_PORTAL_MEMCACHED_LOCATIONS is auto-generated based on
    # jarvice_memcached.enabled/jarvice_memcached.replicaCount
    JARVICE_PORTAL_MEMCACHED_LOCATIONS: # jarvice-memcached-0.jarvice-memcached:11211,jarvice-memcached-1.jarvice-memcached:11211,jarvice-memcached-2.jarvice-memcached:11211
    JARVICE_PORTAL_APP_OWNERS:
    JARVICE_PORTAL_DB: nimbix_portal_ng
    JARVICE_PORTAL_DBHOST: # jarvice-db
    JARVICE_PORTAL_DBUSER: # root
    JARVICE_PORTAL_DBPASSWD: # Pass1234
    # If a non-empty string is passed, the MC portal will not warn about the use of API key related substitutions
    JARVICE_DISABLE_API_SUBST_WARNING: # ""
    # If a non-empty string is passed, the MC portal will use this URL for build and pull web links shown to the user
    JARVICE_API_PUBLIC_URL: # https://<jarvice_api.ingressHost><jarvice_api.ingressPath>
  networkPolicy:
    enabled: # Inherits from jarvice.networkPolicy.enabled if unset
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-bird", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-bird", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-bird", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-bird": "true"}'
  loadBalancerIP:
  ingressHost: # jarvice-bird.my-domain.com
  ingressPath: "/"  # Valid values are "/" (default) or "/bird"
  ingressAnnotations: # '{"nginx.org/client-max-body-size": "0", "nginx.org/proxy-read-timeout": "3600", "nginx.org/proxy-send-timeout": "3600"}'
  bird:
    resources:
      limits:
        cpu: 1
        memory: 1Gi
    readinessProbe:
      initialDelaySeconds: 5
      periodSeconds: 30
      timeoutSeconds: 3
      successThreshold: 1
      failureThreshold: 3
    livenessProbe:
      initialDelaySeconds: 30
      periodSeconds: 60
      timeoutSeconds: 3
      successThreshold: 1
      failureThreshold: 3
  server:
    resources:
      limits:
        cpu: 1
        memory: 1Gi
    readinessProbe:
      initialDelaySeconds: 5
      periodSeconds: 30
      timeoutSeconds: 3
      successThreshold: 1
      failureThreshold: 3
    livenessProbe:
      initialDelaySeconds: 30
      periodSeconds: 60
      timeoutSeconds: 3
      successThreshold: 1
      failureThreshold: 3
    securityContext:
      fsGroup: 890
  portal:
    resources:
      limits:
        cpu: 1
        memory: 2Gi
    readinessProbe:
      initialDelaySeconds: 5
      periodSeconds: 30
      timeoutSeconds: 3
      successThreshold: 1
      failureThreshold: 3
    livenessProbe:
      initialDelaySeconds: 30
      periodSeconds: 60
      timeoutSeconds: 3
      successThreshold: 1
      failureThreshold: 3

keycloakx:
  enabled: false
  create_realm: false
  login:
    KEYCLOAK_RESET_PASSWORD_ALLOWED: true
    KEYCLOAK_REMEMBER_ME: true
  smtpServer: # smtp server settings for keycloak realm
    KEYCLOAK_SMTP_FROM:      # donotreply@example.com
    KEYCLOAK_SMTP_HOST:      # smtp.example.com
    KEYCLOAK_SMTP_PORT:      # 587
    KEYCLOAK_SMTP_START_TLS: # true
    KEYCLOAK_SMTP_AUTH:      # true
    KEYCLOAK_SMTP_USER:      # <user>@smtp.example.com
    KEYCLOAK_SMTP_PASSWORD:  # smtp password
  env:
    JARVICE_KEYCLOAK_ADMIN: jarvice
    JARVICE_KEYCLOAK_ADMIN_PASSWD: Pass1234
    JARVICE_REALM_ADMIN: nimbix
    JARVICE_REALM_ADMIN_PASSWD: abc1234!
  image:
    repository: us-docker.pkg.dev/jarvice-system/images/jarvice-keycloak
    tag: jarvice-master
  imagePullSecrets:
  - name: jarvice-docker
  tolerations:
  - key: node-role.jarvice.io/jarvice-system
    effect: NoSchedule
    operator: Exists
  - key: node-role.kubernetes.io/jarvice-system
    effect: NoSchedule
    operator: Exists
  command:
    - "/opt/keycloak/bin/kc.sh"
    - "--verbose"
    - "start"
    - "--http-enabled=true"
    - "--http-port=8080"
    - "--hostname-strict=false"
    - "--hostname-strict-https=false"
    - "--spi-events-listener-jboss-logging-success-level=info"
    - "--spi-events-listener-jboss-logging-error-level=warn"
    - "--spi-login-protocol-openid-connect-legacy-logout-redirect-uri=true"
  extraEnv: |
    - name: KC_DB_URL
      value: jdbc:mariadb://jarvice-db:3306/keycloak?ssl=allow&createDatabaseIfNotExist=true
    - name: KEYCLOAK_ADMIN
      valueFrom:
        secretKeyRef:
          name: {{ include "keycloak.fullname" . }}-admin-creds
          key: user
    - name: KEYCLOAK_ADMIN_PASSWORD
      valueFrom:
        secretKeyRef:
          name: {{ include "keycloak.fullname" . }}-admin-creds
          key: password
    - name: JAVA_OPTS_APPEND
      value: >-
        -XX:+UseContainerSupport
        -XX:MaxRAMPercentage=50.0
        -Djava.awt.headless=true
        -Djgroups.dns.query={{ include "keycloak.fullname" . }}-headless
  dbchecker:
    enabled: true
  database:
    vendor: mariadb
    hostname: jarvice-db
    port: 3306
    username: root
    password: Pass1234
    database: keycloak
  secrets:
    admin-creds:
      annotations:
        my-test-annotation: Test secret for {{ include "keycloak.fullname" . }}
      stringData:
        user: jarvice
        password: Pass1234
  ingress:
    # If `true`, an Ingress is created
    enabled: true
    # The name of the Ingress Class associated with this ingress
    ingressClassName: "traefik"
    # The Service port targeted by the Ingress
    servicePort: http
    # Ingress annotations
    annotations:
      # cert-manager.io/issuer: letsencrypt-staging
      ## Resolve HTTP 502 error using ingress-nginx:
      ## See https://www.ibm.com/support/pages/502-error-ingress-keycloak-response
      # nginx.ingress.kubernetes.io/proxy-buffer-size: 128k
    # Additional Ingress labels
    labels: {}
    # List of rules for the Ingress
    rules:
      -
        # Ingress host
        host: keycloak.example.com
        # Paths for the host
        paths:
          - path: /
            pathType: Prefix
    # TLS configuration
    tls:
      - hosts:
          - keycloak.example.com
        secretName: "tls-keycloak.example.com"
postgresql:
  enabled: false
