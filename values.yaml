jarvice:
  # imagePullSecret is a base64 encoded string.
  # e.g. - echo "_json_key:$(cat gcr.io.json)" | base64 -w 0
  imagePullSecret:
  JARVICE_LICENSE_LIC:

  # JARVICE_REMOTE_* settings are used for application synchronization
  JARVICE_REMOTE_API_URL: https://cloud.nimbix.net/api
  JARVICE_REMOTE_USER:
  JARVICE_REMOTE_APIKEY:
  JARVICE_APPSYNC_USERONLY: "false"

  JARVICE_LOCAL_REGISTRY: # jarvice-registry:5000
  JARVICE_LOCAL_REPO_BASE: jarvice

  JARVICE_SYSTEM_REGISTRY: gcr.io
  JARVICE_SYSTEM_REPO_BASE: jarvice-system
  JARVICE_IMAGES_TAG: jarvice-master
  JARVICE_IMAGES_VERSION: # auto-set (ignored) if installing from chart repo

  # Optionally, run jobs on a "downstream" cluster by default
  JARVICE_DEFAULT_CLUSTER_URL: # "https://jarvice.downstream-domain.com"

  # If JARVICE_CLUSTER_TYPE is not set to "downstream", an "upstream" cluster
  # deployment/configuration is assumed.
  # If JARVICE_CLUSTER_TYPE is set to "downstream", relevant "upstream"
  # settings in jarvice_* component stanzas are ignored.
  JARVICE_CLUSTER_TYPE: "upstream"  # "downstream"

  # If deploying "downstream" cluster, be sure to set JARVICE_SCHED_SERVER_KEY
  JARVICE_SCHED_SERVER_KEY: # "jarvice-downstream:Pass1234"

  # JARVICE_JOBS_DOMAIN: # jarvice.my-domain.com/job$   # (path based ingress)
  JARVICE_JOBS_DOMAIN: # my-domain.com  # (host based ingress)
  JARVICE_JOBS_LB_SERVICE: "false"
  JARVICE_JOBS_LB_ANNOTATIONS: # '{}'
  JARVICE_JOBS_MULTI_TENANT: "false"
  # At least one of JARVICE_JOBS_MULTI_TENANT_* must be set to a non-empty
  # set/list to enable access to interactive jobs via per job NetworkPolicy
  JARVICE_JOBS_MULTI_TENANT_INGRESS_POD_LABELS: '{}' # '{"app": "traefik"}'
  JARVICE_JOBS_MULTI_TENANT_INGRESS_NS_LABELS: '{}' # '{"name": "kube-system"}'
  JARVICE_JOBS_MULTI_TENANT_LB_SERVICE_CIDRS: '[]' # '["10.20.0.0/24"]'
  JARVICE_JOBS_IMAGE_PULL_POLICY: Always

  # jarvice.tolerations applies to all of the jarvice_* components below.
  # This can be overridden by updating tolerations in each jarvice_* stanza.
  tolerations: '[{"key": "node-role.jarvice.io/jarvice-system", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-system", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-system", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-system", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-system": "true"}'

  # JARVICE_DBHOST and JARVICE_DBUSER only need to change if using a database
  # not provided by this helm chart
  JARVICE_DBHOST: jarvice-db
  JARVICE_DBUSER: root
  JARVICE_DBPASSWD: Pass1234

  JARVICE_PVC_VAULT_NAME: persistent
  JARVICE_PVC_VAULT_STORAGECLASS: jarvice-user
  JARVICE_PVC_VAULT_VOLUMENAME:   # do not use with dynamic provisioning
  JARVICE_PVC_VAULT_ACCESSMODES:  # e.g. "ReadWriteMany,ReadOnlyMany"
  JARVICE_PVC_VAULT_SIZE:         # gigabytes
  JARVICE_PVC_VAULT_SUBPATH:      # optional subpath (supports substitutions)
  JARVICE_PVC_VAULT_ZONE:         # optional zone ID for vault (defaults to 0 - default)

  JARVICE_POD_SCHED_LOGLEVEL: 30
  JARVICE_SCHED_PASS_LOGLEVEL: 30
  JARVICE_SCHED_LOGLEVEL: 30
  JARVICE_K8S_SCHED_LOGLEVEL: 30
  JARVICE_API_LOGLEVEL: 30
  JARVICE_LICENSE_MANAGER_LOGLEVEL: 10

  # JARVICE_LICENSE_MANAGER_URL is auto-set in "upstream" deployments if
  # jarvice_license_manager.enabled is true (may still be modified as needed)
  JARVICE_LICENSE_MANAGER_URL: # "https://jarvice-license-manager.my-domain.com"
  JARVICE_LICENSE_MANAGER_SSL_VERIFY: "true"
  JARVICE_LICENSE_MANAGER_KEY: "jarvice-license-manager:Pass1234"

  JARVICE_MAIL_SERVER: jarvice-smtpd:25
  JARVICE_MAIL_USERNAME: # "mail-username"
  JARVICE_MAIL_PASSWORD: # "Pass1234"
  JARVICE_MAIL_ADMINS: # "admin1@my-domain.com,admin2@my-domain.com"
  JARVICE_MAIL_FROM: "JARVICE Job Status <DoNotReply@localhost>"
  JARVICE_PORTAL_MAIL_FROM: "JARVICE Account Status <DoNotReply@localhost>"
  JARVICE_PORTAL_MAIL_SUBJECT: "Your JARVICE Account"

  # Set to "true" if using SELinux in enforcing mode on hosts targetted for
  # computation, and see SELinux.md for details
  JARVICE_SELINUX_ENFORCING: # "true"

  # uncomment value to relax node weight calculations in order to account
  # for minor inconsequential variance (e.g. when using explicit node selectors
  # any way, such as specific instance types)
  JARVICE_POD_SCHED_LICENSE_PRE: "false"
  JARVICE_POD_SCHED_MULTIPLIERS: # '{"cpu": 0, "memory": 0, "ephemeral-storage": 0, "pods": 0}'

  # Global setting for enabling a secure NetworkPolicy for all JARVICE services
  # The global setting can be overridden within individual services below
  networkPolicy:
    enabled: true

  # Review the following for more information on "skinning" JARVICE with
  # the optional jarvice.settings.configMap:
  # https://github.com/nimbix/jarvice-helm#customize-jarvice-files-via-a-configmap
  settings:
    configMap: jarvice-settings

  JARVICE_SYSTEM_NAMESPACE: # auto-detected, should not need to be updated
  JARVICE_JOBS_NAMESPACE: # auto-set, should not need to be updated
  JARVICE_BUILDS_NAMESPACE: # auto-set, should not need to be updated
  JARVICE_PULLS_NAMESPACE: # auto-set, should not need to be updated
  JARVICE_DAEMONSETS_NAMESPACE: # auto-set, should not need to be updated

  # Optionally, override FQDN used by the API
  # JARVICE_API_PUBLIC_URL: # jarvice-api.my-domain.com # set API URL

  # Optionally, quick enable DaemonSets here.  More details can be found at:
  # https://github.com/nimbix/jarvice-helm#kubernetes-device-plugins
  # https://github.com/nimbix/jarvice-helm#install-recommended-daemonsets
  # If running multiple JARVICE deployments, enable daemonsets for only one.
  daemonsets:
    tolerations: '[{"key": "node-role.jarvice.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "CriticalAddonsOnly", "operator": "Exists"}]'
    nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-compute", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-compute", "operator": "Exists"}]}] }}'
    nodeSelector: # '{"node-role.jarvice.io/jarvice-compute": "true"}'
    cache_pull:
      enabled: false
      tolerations: # '[{"key": "node-role.jarvice.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "CriticalAddonsOnly", "operator": "Exists"}]'
      nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-compute", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-compute", "operator": "Exists"}]}] }}'
      nodeSelector: # '{"node-role.jarvice.io/jarvice-compute": "true"}'
      image: gcr.io/jarvice/jarvice-cache-pull:20201116
      imagePullPolicy: IfNotPresent
    lxcfs:
      enabled: false
      tolerations: # '[{"key": "node-role.jarvice.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "CriticalAddonsOnly", "operator": "Exists"}]'
      nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-compute", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-compute", "operator": "Exists"}]}] }}'
      nodeSelector: # '{"node-role.jarvice.io/jarvice-compute": "true"}'
      image: gcr.io/jarvice/lxcfs:3.0.3-4
      imagePullPolicy: IfNotPresent
      env:
        HOST_LXCFS_DIR: /var/lib/lxcfs
        HOST_LXCFS_INSTALL_DIR: /usr/local/lxcfs-daemonset
    disable_hyper_threading:
      enabled: false
      tolerations: #'[{"key": "node-role.jarvice.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "CriticalAddonsOnly", "operator": "Exists"}]'
      nodeAffinity: '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-compute", "operator": "Exists"}, {"key": "kubernetes.io/arch", "operator": "In", "values": ["amd64"]}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-compute", "operator": "Exists"}, {"key": "kubernetes.io/arch", "operator": "In", "values": ["amd64"]}]}] }}'
      nodeSelector: # '{"node-role.jarvice.io/jarvice-compute": "true", "kubernetes.io/arch": "amd64"}'
      image: gcr.io/jarvice/busybox:latest
      imagePullPolicy: IfNotPresent
    node_init:
      enabled: false
      tolerations: # '[{"key": "node-role.jarvice.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "CriticalAddonsOnly", "operator": "Exists"}]'
      nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-compute", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-compute", "operator": "Exists"}]}] }}'
      nodeSelector: # '{"node-role.jarvice.io/jarvice-compute": "true"}'
      image: gcr.io/jarvice/busybox:latest
      imagePullPolicy: IfNotPresent
      env:
        COMMAND: |
            echo "Disabling kernel check for hung tasks..."
            echo 0 > /proc/sys/kernel/hung_task_timeout_secs || /bin/true
            echo "Disabling kernel check for hung tasks...done."
    nvidia:
      enabled: false
      tolerations: # '[{"key": "node-role.jarvice.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "CriticalAddonsOnly", "operator": "Exists"}]'
      nodeAffinity: '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-compute", "operator": "Exists"}, {"key": "kubernetes.io/arch", "operator": "In", "values": ["amd64", "ppc64le"]}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-compute", "operator": "Exists"}, {"key": "kubernetes.io/arch", "operator": "In", "values": ["amd64", "ppc64le"]}]}] }}'
      nodeSelector: # '{"node-role.jarvice.io/jarvice-compute": "true", "kubernetes.io/arch": "amd64"}'
      image: gcr.io/jarvice/nvidia-k8s-device-plugin:1.11
      imagePullPolicy: IfNotPresent
    nvidia_install:
      enabled: false
      tolerations: # '[{"key": "node-role.jarvice.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "CriticalAddonsOnly", "operator": "Exists"}]'
      nodeAffinity: '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-compute", "operator": "Exists"}, {"key": "kubernetes.io/arch", "operator": "In", "values": ["amd64", "ppc64le"]}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-compute", "operator": "Exists"}, {"key": "kubernetes.io/arch", "operator": "In", "values": ["amd64", "ppc64le"]}]}] }}'
      nodeSelector: # '{"node-role.jarvice.io/jarvice-compute": "true", "kubernetes.io/arch": "amd64"}'
      image: gcr.io/jarvice/busybox:latest
      imagePullPolicy: IfNotPresent
      env:
        NVIDIA_DRIVER_VERSION: 450.102.04-1
    xilinx_fpga:
      enabled: false
      tolerations: # '[{"key": "node-role.jarvice.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "CriticalAddonsOnly", "operator": "Exists"}]'
      # Xilinx FPGA only support amd64 arch
      nodeAffinity: '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-compute", "operator": "Exists"}, {"key": "kubernetes.io/arch", "operator": "In", "values": ["amd64"]}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-compute", "operator": "Exists"}, {"key": "kubernetes.io/arch", "operator": "In", "values": ["amd64"]}]}] }}'
      nodeSelector: # '{"node-role.jarvice.io/jarvice-compute": "true", "kubernetes.io/arch": "amd64"}'
      image: gcr.io/jarvice/xilinx_k8s_fpga_plugin:2020.11.24
      imagePullPolicy: IfNotPresent
    rdma:
      enabled: false
      tolerations: # '[{"key": "node-role.jarvice.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "CriticalAddonsOnly", "operator": "Exists"}, {"key": "jarvice.com/rdma", "operator": "Exists",  "effect": "NoSchedule"}]'
      nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-compute", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-compute", "operator": "Exists"}]}] }}'
      nodeSelector: # '{"node-role.jarvice.io/jarvice-compute": "true"}'
      image: gcr.io/jarvice/k8s-rdma-device:1.0.1
      imagePullPolicy: IfNotPresent
    dri_optional:
      enabled: true
      tolerations: # '[{"key": "node-role.jarvice.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "CriticalAddonsOnly", "operator": "Exists"}]'
      nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-compute", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-compute", "operator": "Exists"}]}] }}'
      nodeSelector: # '{"node-role.jarvice.io/jarvice-compute": "true"}'
      image: gcr.io/jarvice/k8s-dri-optional-device:1.0.2
      imagePullPolicy: IfNotPresent
      env:
        DRI_INIT_DELAY: 1
        DRI_DEFAULT_CAPACITY: 1
    flex_volume_plugin_nfs_nolock_install:
      enabled: true
      tolerations: '[{"key": "node-role.jarvice.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-compute", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.jarvice.io/jarvice-system", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-system", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.jarvice.io/jarvice-storage", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-storage", "effect": "NoSchedule", "operator": "Exists"}]'
      nodeAffinity: '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-compute", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-compute", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-system", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-system", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-storage", "operator": "Exists"}]}, {"matchExpressions": [{"key": "node-role.kubernetes.io/jarvice-storage", "operator": "Exists"}]}] }}'
      nodeSelector: # '{"node-role.jarvice.io/jarvice-compute": "true", "kubernetes.io/arch": "amd64"}'
      image: gcr.io/jarvice/busybox:latest
      imagePullPolicy: IfNotPresent
      env:
        KUBELET_PLUGIN_DIR: /usr/libexec/kubernetes/kubelet-plugins/volume/exec


# Database server previously set up?  Set enabled to false.
jarvice_db: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  enabled: true
  replicaCount: 1
  resources:
    requests:
      cpu: 1
      memory: 2Gi
    limits:
      cpu: 4
      memory: 2Gi
  readinessProbe:
    initialDelaySeconds: 5
    timeoutSeconds: 2
  livenessProbe:
    initialDelaySeconds: 30
    timeoutSeconds: 5
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-db", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-db", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-db", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-db": "true"}'
  networkPolicy:
    enabled: # Inherits from jarvice.networkPolicy.enabled if unset
  image: gcr.io/jarvice/mariadb:10.5
  imagePullPolicy: IfNotPresent
  persistence:
    enabled: false
    # Set to "keep" to prevent removal or jarvice-db-pvc on helm delete
    resourcePolicy: ""  # "keep"
    # Use empty existingClaimName for dynamic provisioning via storageClass
    existingClaimName: # "jarvice-db-pvc"
    # storageClass: "-"
    storageClass: "jarvice-db"
    accessMode: ReadWriteOnce
    size: 8Gi
  securityContext:
    enabled: false  # Enable when PersistentVolume is root squashed
    fsGroup: 999
    runAsUser: 999
  # MYSQL_ROOT_PASSWORD inherits from jarvice.JARVICE_DBPASSWD if unset
  # MYSQL_USER only inherits from jarvice.JARVICE_DBUSER if
  #     jarvice.JARVICE_DBUSER != 'root'
  # MYSQL_PASSWORD is only used if MYSQL_USER is set or
  #     jarvice.JARVICE_DBUSER != 'root'
  # MYSQL_PASSWORD inherits from jarvice.JARVICE_DBPASSWD if unset
  env:
    MYSQL_ROOT_PASSWORD: # Pass1234
    MYSQL_USER: # nimbix # optional, additional superuser
    MYSQL_PASSWORD: # Pass1234

# Enable to use a kubernetes CronJob to regularly dump the JARVICE database
jarvice_db_dump: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  enabled: false
  schedule: "0 4 * * *"
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1
  deleteOldBackups:
    enabled: true
    keep: 14  # Number of dumps to keep
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-db", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-db", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-db", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-db": "true"}'
  persistence:
    # Set to "keep" to prevent removal or jarvice-db-dump-pvc on helm delete
    resourcePolicy: ""  # "keep"
    # Use empty existingClaimName for dynamic provisioning via storageClass
    existingClaimName: # "jarvice-db-dump-pvc"
    # storageClass: "-"
    storageClass: "jarvice-db-dump"
    accessMode: ReadWriteOnce
    size: 50Gi
  securityContext:
    enabled: false  # Enable and set to user and group to use for dump
    fsGroup: 999
    runAsUser: 999

# jarvice_smtpd may be disabled when not set for jarvice.JARVICE_MAIL_SERVER
jarvice_smtpd: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  enabled: true
  replicaCount: 2
  # PodDisruptionBudget default requires 25% minimum of pods must be running
  pdb:
    minAvailable: "25%"
  # antiAffinity default of "soft" prefers that pods run on diff nodes.
  # Set to "hard" to require pods to run on diff nodes.
  antiAffinity: "soft"
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
  readinessProbe:
    initialDelaySeconds: 5
    timeoutSeconds: 2
  livenessProbe:
    initialDelaySeconds: 30
    timeoutSeconds: 5
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-smtpd", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-smtpd", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-smtp", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-smtpd": "true"}'
  networkPolicy:
    enabled: # Inherits from jarvice.networkPolicy.enabled if unset
  image: gcr.io/jarvice/postfix:3.11_3.4.12-r0
  imagePullPolicy: IfNotPresent

# Web service to map a username to full Linux identity based on inspection
# of a shared filesystem:  https://github.com/nimbix/idmapper
# Enable by setting jarvice_idmapper.enabled to true.  Then, configure shared
# filesystem settings under jarvice_idmapper.filesystem and jarvice_idmapper.env
jarvice_idmapper: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  enabled: false
  replicaCount: 2
  # PodDisruptionBudget default requires 25% minimum of pods must be running
  pdb:
    minAvailable: "25%"
  # antiAffinity default of "soft" prefers that pods run on diff nodes.
  # Set to "hard" to require pods to run on diff nodes.
  antiAffinity: "soft"
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
  readinessProbe:
    initialDelaySeconds: 3
    periodSeconds: 15
    timeoutSeconds: 1
    successThreshold: 1
    failureThreshold: 3
  livenessProbe:
    initialDelaySeconds: 3
    periodSeconds: 15
    timeoutSeconds: 1
    successThreshold: 1
    failureThreshold: 2
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-idmapper", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-idmapper", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-idmapper", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-idmapper": "true"}'
  networkPolicy:
    enabled: # Inherits from jarvice.networkPolicy.enabled if unset
  image: gcr.io/jarvice/idmapper:20201116
  imagePullPolicy: IfNotPresent
  # Shared filesystem settings.  Defaults to hostPath if NFS server is not set
  filesystem:
    path: /home
    server: # nfs.my-domain.com
  # Visit https://github.com/nimbix/idmapper for environment variable details
  env:
    HOMEPATH: "/home/%u/"
    UPNPATH: "false"

# Memcached server previously set up?  Set jarvice_memcached.enabled to false.
# Then, set JARVICE_PORTAL_MEMCACHED_LOCATIONS below in jarvice_mc_portal env.
jarvice_memcached: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  enabled: true
  replicaCount: 3
  # PodDisruptionBudget default requires 2 minimum pods must be running
  pdb:
    minAvailable: 2
  # antiAffinity default of "soft" prefers that pods run on diff nodes.
  # Set to "hard" to require pods to run on diff nodes.
  antiAffinity: "soft"
  resources:
    limits:
      cpu: 250m
      memory: 512Mi
  readinessProbe:
    initialDelaySeconds: 5
    timeoutSeconds: 1
  livenessProbe:
    initialDelaySeconds: 30
    timeoutSeconds: 5
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-memcached", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-memcached", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-memcached", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-memcached": "true"}'
  networkPolicy:
    enabled: # Inherits from jarvice.networkPolicy.enabled if unset
  image: gcr.io/jarvice/memcached:1.5
  imagePullPolicy: IfNotPresent
  maxItemMemory: 64
  verbosity: v
  extendedOptions: modern

jarvice_registry:
  enabled: false
  replicaCount: 1
  loadBalancerIP:
  ingressHost: # jarvice-registry.my-domain.com
  ingressPath: "/"  # Valid values are "/" (default) or "/registry"
  resources:
    limits:
      cpu: 250m
      memory: 512Mi
  readinessProbe:
    initialDelaySeconds: 5
    timeoutSeconds: 1
  livenessProbe:
    initialDelaySeconds: 30
    timeoutSeconds: 5
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-registry", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-registry", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-registry", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-registry": "true"}'
  networkPolicy:
    enabled: # Inherits from jarvice.networkPolicy.enabled if unset
  image: registry:2
  imagePullPolicy: IfNotPresent
  persistence:
    enabled: false
    # Set to "keep" to prevent removal or jarvice-registry-pvc on helm delete
    resourcePolicy: ""  # "keep"
    # Use empty existingClaimName for dynamic provisioning via storageClass
    existingClaimName: # "jarvice-registry-pvc"
    # storageClass: "-"
    storageClass: "jarvice-registry"
    accessMode: ReadWriteOnce
    size: 10Gi
  env:
    REGISTRY_HTTP_ADDR: 0.0.0.0:5000

jarvice_dal: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  enabled: true
  replicaCount: 2
  replicaCountMax: 6
  # HorizontalPodAutoscaler is enabled when replicaCountMax > replicaCount
  autoscaling:
    metrics:
      - type: Resource
        resource:
          name: cpu
          target:
            type: Utilization
            averageUtilization: 60
      - type: Resource
        resource:
          name: memory
          target:
            type: Utilization
            averageUtilization: 60
  # PodDisruptionBudget default requires 25% minimum of pods must be running
  pdb:
    minAvailable: "25%"
  # antiAffinity default of "soft" prefers that pods run on diff nodes.
  # Set to "hard" to require pods to run on diff nodes.
  antiAffinity: "soft"
  resources:
    requests:
      cpu: 2
      memory: 8Gi
    limits:
      cpu: 8
      memory: 8Gi
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 30
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 60
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  hostNetwork: false
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-dal", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-dal", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-dal", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-dal": "true"}'
  networkPolicy:
    enabled: # Inherits from jarvice.networkPolicy.enabled if unset
  # jarvice.settings.configMap takes precedence over environment settings
  # for JARVICE_CFG_NETWORK
  # JARVICE_SITE_DBHOST inherits from jarvice.JARVICE_DBHOST if unset
  # JARVICE_SITE_DBPASSWD inherits from jarvice.JARVICE_DBPASSWD if unset
  # JARVICE_SITE_DBUSER inherits from jarvice.JARVICE_DBUSER if unset
  env:
    JARVICE_SITE_DBHOST: # jarvice-db
    JARVICE_SITE_DBUSER: # root
    JARVICE_SITE_DBPASSWD: # Pass1234
    JARVICE_ROOT_USER_CREATE: False
    JARVICE_ROOT_USER_PASSWD: Pass1234
    JARVICE_ROOT_USER_EMAIL: root@localhost
    JARVICE_USER_REGISTRY_VERIFY: False
    JARVICE_ROOT_USER_VAULT: # default-BLOCK-1GB
    JARVICE_ROOT_USER_VAULT_SIZE: # 1
    JARVICE_MACHINES_ADD: '[{"mc_name":"n0", "mc_description":"2 core, 16GB RAM (CPU only)", "mc_cores":"2", "mc_slots":"2", "mc_gpus":"0", "mc_ram":"16", "mc_swap":"8", "mc_scratch":"64", "mc_devices":"", "mc_properties":"", "mc_slave_properties":"", "mc_slave_gpus":"0", "mc_slave_ram":"16", "mc_scale_min":"1", "mc_scale_max":"1", "mc_scale_select":"", "mc_lesser":"1", "mc_price":"0.00", "mc_priority":"0", "mc_privs":"", "mc_arch":"x86_64"}, {"mc_name":"n1", "mc_description":"4 core, 32GB RAM (CPU Only)", "mc_cores":"4", "mc_slots":"4", "mc_gpus":"0", "mc_ram":"32", "mc_swap":"16", "mc_scratch":"100", "mc_devices":"", "mc_properties":"", "mc_slave_properties":"", "mc_slave_gpus":"0", "mc_slave_ram":"32", "mc_scale_min":"1", "mc_scale_max":"1", "mc_scale_select":"", "mc_lesser":"1", "mc_price":"0.00", "mc_priority":"0", "mc_privs":"", "mc_arch":"x86_64"}, {"mc_name":"n3", "mc_description":"16 core, 128GB RAM (CPU Only)", "mc_cores":"16", "mc_slots":"16", "mc_gpus":"0", "mc_ram":"128", "mc_swap":"64", "mc_scratch":"500", "mc_devices":"", "mc_properties":"", "mc_slave_properties":"", "mc_slave_gpus":"0", "mc_slave_ram":"128", "mc_scale_min":"1", "mc_scale_max":"256", "mc_scale_select":"", "mc_lesser":"1", "mc_price":"0.00", "mc_priority":"0", "mc_privs":"", "mc_arch":"x86_64"}]'
    JARVICE_CFG_NETWORK: |
        [global]
        netmask: 255.255.0.0
        gateway: 172.17.0.1
        dns: 8.8.8.8,8.8.4.4
        search: localdomain,dev.nimbix.net,nimbix.net
        linuxbr: docker0
        naelimit: 0
        nae_nfs_bind: 172.17.0.0/16
        [floating]
        start: 172.17.0.100
        end: 172.17.0.255
        [nat]
        [static]
        [fqdns]
        [naelimits]
    JARVICE_NODE_ENV: production

jarvice_scheduler: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  enabled: true
  replicaCount: 2
  # PodDisruptionBudget default requires 25% minimum of pods must be running
  pdb:
    minAvailable: "25%"
  # antiAffinity default of "soft" prefers that pods run on diff nodes.
  # Set to "hard" to require pods to run on diff nodes.
  antiAffinity: "soft"
  resources:
    limits:
      cpu: 1
      memory: 2Gi
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 30
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 60
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-scheduler", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-scheduler", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-scheduler", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-scheduler": "true"}'
  networkPolicy:
    enabled: # Inherits from jarvice.networkPolicy.enabled if unset
  env:
    JARVICE_SCHED_PASS_INTERVAL: 5
    JARVICE_SCHED_CLUSTERS_TIMEOUT: 20

jarvice_k8s_scheduler:
  enabled: true
  replicaCount: 2
  # PodDisruptionBudget default requires 25% minimum of pods must be running
  pdb:
    minAvailable: "25%"
  # antiAffinity default of "soft" prefers that pods run on diff nodes.
  # Set to "hard" to require pods to run on diff nodes.
  antiAffinity: "soft"
  # loadBalancerIP and ingressHost are only applicable when
  # jarvice.JARVICE_CLUSTER_TYPE is set to "downstream"
  loadBalancerIP:
  ingressHost: # jarvice-k8s-scheduler.my-domain.com
  resources:
    limits:
      cpu: 1
      memory: 2Gi
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 30
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 60
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-k8s-scheduler", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-k8s-scheduler", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-k8s-scheduler", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-k8s-scheduler": "true"}'
  networkPolicy:
    enabled: # Inherits from jarvice.networkPolicy.enabled if unset
  env:
    JARVICE_UNFS_REQUEST_MEM: 1Gi
    JARVICE_UNFS_REQUEST_CPU: 1
    JARVICE_UNFS_EXPIRE_SECS: 90
    JARVICE_UNFS_NODE_SELECTOR: # '{"node-role.jarvice.io/jarvice-storage": "true"}' # '{"node-role.kubernetes.io/jarvice-storage": "true"}'
    JARVICE_UNFS3_IMAGE: # gcr.io/jarvice/unfs3:20190318-1 - change if mirroring locally
    JARVICE_PVCLS_IMAGE: # alpine:3.8 - change if mirroring locally
    JARVICE_SCHED_JOB_UID:  # set to numeric value to override UID for jobs
    JARVICE_SCHED_JOB_GID:  # set to numeric value to override GID for jobs

jarvice_pod_scheduler:
  enabled: true
  resources:
    limits:
      cpu: 1
      memory: 2Gi
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 30
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 60
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-pod-scheduler", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-pod-scheduler", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-pod-scheduler", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-pod-scheduler": "true"}'
  env:
    JARVICE_POD_SCHED_NAME:  # auto-set, should not need to be updated

# jarvice-license-manager runs on amd64 nodes only. In a multi-arch cluster, it
# may be necessary to set tolerations, nodeAffinity, and/or nodeSelector.
# Also, create/update jarvice-license-manager ConfigMap w/ servers.json data
# Uses "user:password" pair set in jarvice.JARVICE_LICENSE_MANAGER_KEY
jarvice_license_manager: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  enabled: false
  loadBalancerIP:
  ingressHost: # jarvice-license-manager.my-domain.com
  resources:
    limits:
      cpu: 1
      memory: 2Gi
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 30
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 60
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-license-manager", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-license-manager", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "kubernetes.io/arch", "operator": "In", "values": ["amd64"]}]}] }}'  # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-license-manager", "operator": "Exists"}, {"key": "kubernetes.io/arch", "operator": "In", "values": ["amd64"]}]}] }}'
  nodeSelector: # '{"kubernetes.io/arch": "amd64"}'  # '{"node-role.jarvice.io/jarvice-license-manager": "true", "kubernetes.io/arch": "amd64"}'
  networkPolicy:
    enabled: # Inherits from jarvice.networkPolicy.enabled if unset
  env:
    JARVICE_HOSTALIASES: # '[ {"ip": "10.20.0.1", "hostnames": ["hostname-1a"]}, {"ip": "10.20.0.2", "hostnames": ["hostname-2a", "hostname-2b"]} ]'
    JARVICE_LMSTAT_INTERVAL: 60
    JARVICE_S3_BUCKET:
    JARVICE_S3_ACCESSKEY:
    JARVICE_S3_SECRETKEY:
    JARVICE_S3_ENDPOINTURL: # https://s3.my-domain.com

jarvice_api: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  enabled: true
  replicaCount: 2
  replicaCountMax: 6
  # HorizontalPodAutoscaler is enabled when replicaCountMax > replicaCount
  autoscaling:
    metrics:
      - type: Resource
        resource:
          name: cpu
          target:
            type: Utilization
            averageUtilization: 60
      - type: Resource
        resource:
          name: memory
          target:
            type: Utilization
            averageUtilization: 60
  # PodDisruptionBudget default requires 25% minimum of pods must be running
  pdb:
    minAvailable: "25%"
  # antiAffinity default of "soft" prefers that pods run on diff nodes.
  # Set to "hard" to require pods to run on diff nodes.
  antiAffinity: "soft"
  loadBalancerIP:
  ingressHost: # jarvice-api.my-domain.com
  ingressPath: "/"  # Valid values are "/" (default) or "/api"
  resources:
    limits:
      cpu: 1
      memory: 256Mi
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 30
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 60
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-api", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-api", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-api", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-api": "true"}'
  networkPolicy:
    enabled: # Inherits from jarvice.networkPolicy.enabled if unset

jarvice_dockerbuild: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-dockerbuild", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-dockerbuild", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-dockerbuild": "true"}'

jarvice_dockerpull: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-dockerpull", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-dockerpull", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-dockerpull": "true"}'

jarvice_appsync: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  enabled: true
  replicaCount: 1
  resources:
    limits:
      cpu: 250m
      memory: 1Gi
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 30
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 60
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-appsync", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-appsync", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-appsync", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-appsync": "true"}'
  # If JARVICE_SYSTEM_REGISTRY and/or JARVICE_SYSTEM_REPO_BASE are not set in
  # jarvice_appsync.env, they will be set via the global jarvice stanza above.
  env:
    JARVICE_SYSTEM_REGISTRY: # gcr.io
    JARVICE_SYSTEM_REPO_BASE: jarvice-apps
    JARVICE_APPSYNC_INTERVAL: 3600
  livenessProbe:
    periodSeconds: 900

jarvice_mc_portal: # N/A if jarvice.JARVICE_CLUSTER_TYPE: "downstream"
  enabled: true
  replicaCount: 2
  replicaCountMax: 6
  # HorizontalPodAutoscaler is enabled when replicaCountMax > replicaCount
  autoscaling:
    metrics:
      - type: Resource
        resource:
          name: cpu
          target:
            type: Utilization
            averageUtilization: 60
      - type: Resource
        resource:
          name: memory
          target:
            type: Utilization
            averageUtilization: 60
  # PodDisruptionBudget default requires 25% minimum of pods must be running
  pdb:
    minAvailable: "25%"
  # antiAffinity default of "soft" prefers that pods run on diff nodes.
  # Set to "hard" to require pods to run on diff nodes.
  antiAffinity: "soft"
  loadBalancerIP:
  ingressHost: # jarvice.my-domain.com
  ingressPath: "/"  # Valid values are "/" (default) or "/portal"
  resources:
    limits:
      cpu: 1
      memory: 2Gi
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 30
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 60
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3
  tolerations: # '[{"key": "node-role.jarvice.io/jarvice-mc-portal", "effect": "NoSchedule", "operator": "Exists"}, {"key": "node-role.kubernetes.io/jarvice-mc-portal", "effect": "NoSchedule", "operator": "Exists"}]'
  nodeAffinity: # '{"requiredDuringSchedulingIgnoredDuringExecution": {"nodeSelectorTerms": [{"matchExpressions": [{"key": "node-role.jarvice.io/jarvice-mc-portal", "operator": "Exists"}]}] }}'
  nodeSelector: # '{"node-role.jarvice.io/jarvice-mc-portal": "true"}'
  networkPolicy:
    enabled: # Inherits from jarvice.networkPolicy.enabled if unset
  # JARVICE_PORTAL_DBHOST inherits from jarvice.JARVICE_DBHOST if unset
  # JARVICE_PORTAL_DBPASSWD inherits from jarvice.JARVICE_DBPASSWD if unset
  # JARVICE_PORTAL_DBUSER inherits from jarvice.JARVICE_DBUSER if unset
  # JARVICE_PORTAL_WEB_HOST inherits from jarvice_mc_portal.ingressHost/jarvice_mc_portal.ingressPath if unset
  env:
    JARVICE_USER_DEFAULT_ENABLED: True
    JARVICE_USER_DEFAULT_DEVELOPER: True
    JARVICE_PORTAL_GSS_REALM:
    JARVICE_PORTAL_GSS_DOMAIN:
    JARVICE_PORTAL_GSS_LOG: # "debug"
    JARVICE_PORTAL_WEB_HOST: # https://<jarvice_mc_portal.ingressHost><jarvice_mc_portal.ingressPath>
    # If null, JARVICE_PORTAL_MEMCACHED_LOCATIONS is auto-generated based on
    # jarvice_memcached.enabled/jarvice_memcached.replicaCount
    JARVICE_PORTAL_MEMCACHED_LOCATIONS: # jarvice-memcached-0.jarvice-memcached:11211,jarvice-memcached-1.jarvice-memcached:11211,jarvice-memcached-2.jarvice-memcached:11211
    JARVICE_PORTAL_APP_OWNERS:
    JARVICE_PORTAL_DB: nimbix_portal_ng
    JARVICE_PORTAL_DBHOST: # jarvice-db
    JARVICE_PORTAL_DBUSER: # root
    JARVICE_PORTAL_DBPASSWD: # Pass1234
    # If a non-empty string is passed, the MC portal will not warn about the use of API key related substitutions
    JARVICE_DISABLE_API_SUBST_WARNING: # ""
    # If a non-empty string is passed, the MC portal will use this URL for build and pull web links shown to the user
    JARVICE_API_PUBLIC_URL: # https://<jarvice_api.ingressHost><jarvice_api.ingressPath>

